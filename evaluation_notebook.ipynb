{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xlrd in /home/brandon/.local/lib/python3.8/site-packages (2.0.1)\r\n"
     ]
    }
   ],
   "source": [
    "from random \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tok2vec', 'ner']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "import re\n",
    "import os\n",
    "from spacy import displacy\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "FOODKEEPER_PATH = \"datasets/FoodKeeper-Data.xls\"\n",
    "TRAINING_DATA_PATH = \"datasets/data.csv\"\n",
    "MODEL_PATH = \"output/model-last\"\n",
    "TEST_DATA_PATH = \"datasets/test_data.csv\"\n",
    "\n",
    "#STARTING_KEYWORD_COUNT = 10\n",
    "#TRAINING_LOOP_ITERATIONS = 3\n",
    "#REQUIRED_KEYWORDS = 3\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "nlp = spacy.load(MODEL_PATH)\n",
    "food_data = pd.read_excel(FOODKEEPER_PATH, sheet_name = \"Product\")\n",
    "training_data = pd.read_csv(TRAINING_DATA_PATH,index_col = False, header = None)\n",
    "test_data = pd.read_csv(TEST_DATA_PATH)\n",
    "\n",
    "#write a method to find the top x keywords in the dataset\n",
    "#loop through and count the specific entities\n",
    "keywords = [] #'chicken', 'milk', 'butter', 'cheese'\n",
    "sampleData = []\n",
    "\n",
    "\n",
    "    \n",
    "#update rank tweet to take the counter as a parameter and condense both rankings\n",
    "def rankTweet(tweet):\n",
    "    tweetKeywords = []\n",
    "    doc = nlp(tweet)\n",
    "    return len(doc.ents)\n",
    "       \n",
    "        \n",
    "    print(tweetKeywords)\n",
    "    \n",
    "def findNewKeywords(tweet, keywords):\n",
    "    foodkeeperKeys = foodKeeperInfo()\n",
    "    x = tweet.split()\n",
    "    word = \"\"\n",
    "    i = 0\n",
    "    while i < len(x):\n",
    "    #for i in range(len(x)):\n",
    "        z = 1\n",
    "        if x[i] in foodkeeperKeys:\n",
    "            word = x[i]\n",
    "        try:\n",
    "            foundBiWord = x[i] + \" \" + x[i+1]\n",
    "            if foundBiWord in keywords:\n",
    "                word = foundBiWord\n",
    "                z = 2\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        try:\n",
    "            foundTriWord = x[i] + \" \" + x[i+1] + \" \" + x[i+2]\n",
    "            if foundTriWord in keywords:\n",
    "                word = foundTriWord\n",
    "                z = 3\n",
    "        except:\n",
    "            pass\n",
    "        i += z\n",
    "        \n",
    "        if word not in keywords and word != \"\":\n",
    "            keywords.append(word)\n",
    "    #print(keywords)\n",
    "    \n",
    "#def findInitialKeywords(data):\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "keywordRanker = {}   \n",
    "\n",
    "def convertToTrainingFormat(tweet, keywords):\n",
    "    \n",
    "    \n",
    "    x = tweet.split()\n",
    "    myEnts = {'entities':[]}\n",
    "    found = False\n",
    "    i = 0\n",
    "    while i < len(x):\n",
    "        z = 1\n",
    "        newWord = \"\"\n",
    "        if x[i] in keywords:\n",
    "            pos = tweet.find(x[i])\n",
    "            y = (pos, pos + len(x[i]), 'FOOD')\n",
    "            found = True\n",
    "        if x[i] in foodKeeperKeywordsTest:\n",
    "            newWord = x[i]\n",
    "            \n",
    "        try:\n",
    "            foundBiWord = x[i] + \" \" + x[i+1]\n",
    "            if foundBiWord in keywords:\n",
    "                pos = tweet.find(x[i])\n",
    "                y = (pos, pos + len(x[i])+len(x[i+1]) + 1, 'FOOD')\n",
    "                found = True\n",
    "                z = 2\n",
    "            if foundBiWord in foodKeeperKeywordsTest:\n",
    "                newWord = foundBiWord\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            foundTriWord = x[i] + \" \" + x[i+1] + \" \" + x[i+2]\n",
    "            if foundTriWord in keywords:\n",
    "                pos = tweet.find(x[i])\n",
    "                y = (pos, pos + len(x[i])+len(x[i+1])+len(x[i+2]) + 2, 'FOOD')\n",
    "                found = True\n",
    "                z = 3\n",
    "            if foundTriWord in foodKeeperKeywordsTest:\n",
    "                newWord = foundTriWord\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            if y not in myEnts['entities']:\n",
    "                myEnts['entities'].append(y) \n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        \n",
    "        if newWord != \"\" and newWord not in keywordRanker:\n",
    "            keywordRanker[newWord] = 1\n",
    "        elif newWord != \"\" and newWord in keywordRanker:\n",
    "            keywordRanker[newWord] += 1\n",
    "        #print(z)\n",
    "        i += z\n",
    "        #print(i)\n",
    "        \n",
    "        \n",
    "    formatted = (tweet, myEnts)\n",
    "    #print(formatted)\n",
    "    if found:\n",
    "        return formatted\n",
    "    else: return ()\n",
    "   \n",
    "    \n",
    "\n",
    "#print(convertToTrainingFormat('I like chicken and salsa', keywords))\n",
    "\n",
    "#print(food_data['Keywords'])\n",
    "\n",
    "def foodKeeperInfo():              \n",
    "    keywords = []\n",
    "    for word in food_data['Name']:\n",
    "        word = word.lstrip()\n",
    "        word = word.rstrip()\n",
    "\n",
    "        if word.lower() not in keywords: \n",
    "            keywords.append(word.lower())\n",
    "\n",
    "    #print(\"Total foodkeeper food names: \" + str(len(keywords)))        \n",
    "    #for element in sorted(keywords):\n",
    "        #print(element)\n",
    "        \n",
    "    return keywords\n",
    "\n",
    "foodKeeperKeywordsTest = foodKeeperInfo()\n",
    "\n",
    "\n",
    "def preProcess(tweet):\n",
    "    #Converts a tweet to lowercase, replaces anyusername w/ <USERNAME> and URLS with <URL>\n",
    "    #tweet = tweet.lower()\n",
    "    #tweet = re.sub('@[a-zA-z0-9]*', '<USERNAME>', tweet)\n",
    "    #tweet = re.sub('https[a-zA-z0-9./:]*', '<URL>', tweet)\n",
    "    #tweet = re.sub('[.,-]*', '', tweet)\n",
    "    \n",
    "    return tweet\n",
    "\n",
    "\n",
    "noEntity= []\n",
    "               \n",
    "           \n",
    "def trainModel(data):\n",
    "    \n",
    "    oldKeywords = []\n",
    "    newKeywords = []\n",
    "    \n",
    "    #controls how many entities are required to accept add a Tweet to be trained\n",
    "    entityCheckCount = 3\n",
    "    \n",
    "    counter = 0\n",
    "    trainingLoop = True\n",
    "    \n",
    "    while trainingLoop:\n",
    "        print(\"~~~~~~~~~~~~~~~~~\"+str(counter)+\"~~~~~~~~~~~~~~~~~\")\n",
    "        nlp = spacy.blank(\"en\") # load a new spacy model\n",
    "        db = DocBin() # create a DocBin object\n",
    "\n",
    "        myTweets = []\n",
    "        #Loop through all the tweets\n",
    "        #print(keywordRanker)\n",
    "        for i in range(len(data[0])):\n",
    "            \n",
    "            if counter == 1:\n",
    "                x = convertToTrainingFormat(preProcess(data[0][i]), keywords)\n",
    "                if x!= ():\n",
    "                    if len(x[1]['entities']) > entityCheckCount:\n",
    "                        #print(\"Found tweet\", x[0])\n",
    "                        \n",
    "                        myTweets.append(x)  \n",
    "        \n",
    "            else:\n",
    "                #convert each tweet into spacy training format\n",
    "                x = convertToTrainingFormat(preProcess(data[0][i]), keywords)\n",
    "                if x != ():\n",
    "                    #print(len(x[1]['entities'])\n",
    "                    #check the ranking of the tweet\n",
    "                    if rankTweet(x[0]) > entityCheckCount:\n",
    "                        #print(\"Checking rank...\")\n",
    "                        myTweets.append(x)\n",
    "\n",
    "                        \n",
    "        #Initialize the keywords\n",
    "        #print(\"\\n\\n\\nKeyword Ranker\\n\")\n",
    "        sortedKeywords =  sorted(keywordRanker, key=keywordRanker.get, reverse=True)\n",
    "        \n",
    "        #Chooses first 10 keywords to be used as basis for Snowball\n",
    "        if counter == 0: \n",
    "            for i in range(15):\n",
    "                keywords.append(sortedKeywords[i])\n",
    "            #print(sortedKeywords[i], keywordRanker[sortedKeywords[i]])\n",
    "                \n",
    "        if counter > 0:\n",
    "            for text, annot in tqdm(myTweets): # data in previous format\n",
    "                doc = nlp.make_doc(text) # create doc object from text\n",
    "                ents = []\n",
    "                for start, end, label in annot[\"entities\"]: # add character indexes\n",
    "                    span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n",
    "                    if span is None:\n",
    "                        print(\"Skipping entity\")\n",
    "                    else:\n",
    "                        ents.append(span)\n",
    "                doc.ents = ents # label the text with the ents\n",
    "                db.add(doc)\n",
    "\n",
    "                db.to_disk(\"./train.spacy\") # save the docbin object\n",
    "\n",
    "            stream = os.popen('python3 -m spacy train config.cfg --output ./output --paths.train ./train.spacy --paths.dev ./train.spacy')\n",
    "            print(stream.read())\n",
    "            print(\"Total keywords: \", str(len(keywords)))\n",
    "            print(\"List of Keywords:\\n\\n\",keywords,\"\\n\\n\")\n",
    "            oldKeywords = len(keywords)\n",
    "            for element in myTweets:\n",
    "                findNewKeywords(element[0], keywords)\n",
    "            if (oldKeywords == len(keywords)) and counter > 1 and entityCheckCount != 1:\n",
    "                print(\"Decreasing entityCheckCount variable by 1\")\n",
    "                entityCheckCount -= 1\n",
    "            elif (oldKeywords == len(keywords)) and counter > 1 and entityCheckCount == 1:\n",
    "                trainingLoop = False\n",
    "            \n",
    "            eval_model()\n",
    "            \n",
    "        \n",
    "\n",
    "        #for element in myTweets:\n",
    "            #findNewKeywords(element[0], keywords)\n",
    "\n",
    "        print(\"Total keywords: \", str(len(keywords)))\n",
    "        print(\"Total Tweets: \", str(len(myTweets)))\n",
    "        print(\"List of Keywords:\\n\\n\",keywords,\"\\n\\n\")\n",
    "        counter += 1\n",
    "        \n",
    "    print('Training Done...')\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "def information(data):\n",
    "    myData = {}\n",
    "    totalEnt=0\n",
    "    \n",
    "    for i in range(len(data[0])):\n",
    "        doc = nlp(preProcess(data[0][i]))\n",
    "        if len(doc.ents) == 0:\n",
    "            noEntity.append(preProcess(data[0][i]))\n",
    "            \n",
    "        #print(len(doc.ents))\n",
    "        if(len(doc.ents) == 4):\n",
    "            print(doc)\n",
    "            \n",
    "        for entity in doc.ents: \n",
    "        #print(entity.label_)\n",
    "            totalEnt+=1\n",
    "            if(entity.label_ == 'FOOD'):\n",
    "                if entity.text in myData:\n",
    "                    myData[entity.text] += 1\n",
    "                else:\n",
    "                    myData[entity.text] = 1\n",
    "                    \n",
    "    print(\"Number of entities found: \" + str(len(myData)))\n",
    "    print(totalEnt)\n",
    "    for i in sorted(myData, key = myData.get):\n",
    "        print(\"Entity: \" + i, \"Count: \" + str(myData[i]), \"Density: \" + str(format(myData[i]/totalEnt, '.2f')), end = \"\\n\")\n",
    "    \n",
    "    \n",
    "    return myData\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(test_data['tweet'])):\n",
    "    test_data['tweet'][i] = preProcess(test_data['tweet'][i])\n",
    "\n",
    "\n",
    "\n",
    "y = test_data['food'].tolist()\n",
    "print(nlp.pipe_names)\n",
    "    \n",
    "def ent_recognize(text):\n",
    "    doc = nlp(text)\n",
    "    displacy.render(doc,style = \"ent\")\n",
    "    \n",
    "def predict(tweet):\n",
    "    doc = nlp(str(tweet))\n",
    "    if doc.ents:\n",
    "        displacy.render(doc,style = \"ent\")\n",
    "\n",
    "def returnPrediction(tweet):\n",
    "    nlp = spacy.load(MODEL_PATH)\n",
    "    doc = nlp(str(tweet))\n",
    "    if doc.ents:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def get_predictions():\n",
    "    predictions = []\n",
    "    for tweet in test_data['tweet'].tolist():\n",
    "        predictions.append(returnPrediction(tweet))\n",
    "    return predictions\n",
    "    \n",
    "def eval_model():\n",
    "    nlp = spacy.load(MODEL_PATH)\n",
    "    predictions = get_predictions()\n",
    "    print(metrics.confusion_matrix(y,predictions, labels = [1,0]))\n",
    "    print(metrics.classification_report(y,predictions, labels = [1,0]))\n",
    "    \n",
    "def show_tp():\n",
    "    counter = 0\n",
    "    tweets = test_data['tweet'].tolist()\n",
    "    predictions = get_predictions()\n",
    "    for i in range(len(y)):\n",
    "        if predictions[i] == 1 and y[i] == 1:\n",
    "            print(\"True positives:\", tweets[i], \"\\n\")\n",
    "            counter += 1\n",
    "    print(counter)\n",
    "    \n",
    "def show_tn():\n",
    "    counter = 0\n",
    "    predictions = get_predictions()\n",
    "    tweets = test_data['tweet'].tolist()\n",
    "    for i in range(len(y)):\n",
    "        if predictions[i] == 0 and y[i] == 0:\n",
    "            print(\"True Negative:\", tweets[i], \"\\n\")\n",
    "            counter += 1\n",
    "    print(counter)\n",
    "    \n",
    "def show_fn():\n",
    "    predictions = get_predictions()\n",
    "    tweets = test_data['tweet']\n",
    "    counter = 0\n",
    "    for i in range(len(y)):\n",
    "        if predictions[i] == 0 and y[i] == 1:\n",
    "            print(\"False Negative:\", tweets[i], \"\\n\")\n",
    "            counter += 1\n",
    "    print(counter)\n",
    "    \n",
    "def show_fp():\n",
    "    predictions = get_predictions()\n",
    "    tweets = test_data['tweet'].tolist()\n",
    "    for i in range(len(y)):\n",
    "        if predictions[i] == 1 and y[i] == 0:\n",
    "            print(\"False Positive:\")\n",
    "            doc = nlp(str(tweets[i]))\n",
    "            if doc.ents:\n",
    "                displacy.render(doc,style = \"ent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the function below to check individual sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">My \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    chicken\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">FOOD</span>\n",
       "</mark>\n",
       " is tasty</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ent_recognize(\"My chicken is tasty\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the function below to check model performance on the entire test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0 44]\n",
      " [ 0 39]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00        44\n",
      "           0       0.47      1.00      0.64        39\n",
      "\n",
      "    accuracy                           0.47        83\n",
      "   macro avg       0.23      0.50      0.32        83\n",
      "weighted avg       0.22      0.47      0.30        83\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brandon/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/brandon/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/brandon/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "eval_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the functions below to see TP, TN, FP, FN respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_tp()\n",
    "# show_tn()\n",
    "# show_fp()\n",
    "#show_fn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-2716a7f28add>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmyTrainingdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minformation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-0ce7d2b2f97b>\u001b[0m in \u001b[0;36minformation\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ments\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mnoEntity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/spacy/language.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[1;32m    981\u001b[0m         \u001b[0mDOCS\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mhttps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;31m#call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m         \"\"\"\n\u001b[0;32m--> 983\u001b[0;31m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_doc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    984\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcomponent_cfg\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m             \u001b[0mcomponent_cfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/spacy/language.py\u001b[0m in \u001b[0;36mmake_doc\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m   1063\u001b[0m                 \u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE088\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1064\u001b[0m             )\n\u001b[0;32m-> 1065\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1066\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1067\u001b[0m     def update(\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/spacy/tokenizer.pyx\u001b[0m in \u001b[0;36mspacy.tokenizer.Tokenizer.__call__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/spacy/tokenizer.pyx\u001b[0m in \u001b[0;36mspacy.tokenizer.Tokenizer._tokenize_affixes\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/spacy/tokenizer.pyx\u001b[0m in \u001b[0;36mspacy.tokenizer.Tokenizer._tokenize\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/spacy/tokenizer.pyx\u001b[0m in \u001b[0;36mspacy.tokenizer.Tokenizer._attach_tokens\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/spacy/vocab.pyx\u001b[0m in \u001b[0;36mspacy.vocab.Vocab.get\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/spacy/vocab.pyx\u001b[0m in \u001b[0;36mspacy.vocab.Vocab._new_lexeme\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/spacy/lang/lex_attrs.py\u001b[0m in \u001b[0;36mlower\u001b[0;34m(string)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "myTrainingdata = information(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Tweets where no entities were found:  12716 \n",
      "\n",
      "<USERNAME> billie is butter?\n",
      "\"the anasa life coco smooth body butter is soooo amazing. i got the yuce scent, which is light and citrusy. the texture is so soft, and not too heavy or oily. it's absolutely perfect. if you love natural, quality body products, get this...\" - arielle b.\n",
      "dairy. all dairy products, like milk, butter, yogurt, and cheese, must come from a kosher animal.\n",
      "<USERNAME> bread , butter and sugar !!!\n",
      "i use body butter. but, yes after every bath/shower! it’s so important to moisturize! <URL>\n",
      "<USERNAME> billie is butter?\n",
      "as the brand &amp; content lead of <USERNAME>, buzzfeed's black culture vertical, <USERNAME> aims to \"push the culture forward.\"  \"life is so short, so while i'm here, i'm going to disrupt some things, shake the table, and make my presence known.\" <URL>\n",
      "<USERNAME> like. butter bread\n",
      "<USERNAME> <USERNAME> <USERNAME> love that video!!!!! so does peanut butter!!!!!!\n",
      "<USERNAME> <USERNAME> <USERNAME> a bit coin can buy over 3x as much milk, butter, gas, etc. as it could just a few years ago.  not so for the usd.  so the dollar is more stable.\n"
     ]
    }
   ],
   "source": [
    "#Tweets where no entities were found\n",
    "print(\"Number of Tweets where no entities were found: \", len(noEntity), '\\n')\n",
    "\n",
    "for i in range(10):\n",
    "    print(noEntity[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total foodkeeper food names: 466\n",
      "\"genuine\" maple syrup\n",
      "aioli\n",
      "almond butter\n",
      "almond extract\n",
      "almond milk\n",
      "almond oil\n",
      "almonds\n",
      "amaranth\n",
      "anchovies\n",
      "apple cider\n",
      "apple cider vinegar\n",
      "apple juice\n",
      "apples\n",
      "applesauce\n",
      "apricots\n",
      "artichokes, whole\n",
      "arugula\n",
      "asparagus\n",
      "avocado oil\n",
      "avocados\n",
      "baby carrots\n",
      "bacon\n",
      "bacon bits\n",
      "bacon grease\n",
      "bagel\n",
      "bagged greens\n",
      "baking powder\n",
      "baking soda\n",
      "balsamic vinegar\n",
      "bamboo shoots\n",
      "bananas\n",
      "barbecue sauce\n",
      "barley\n",
      "base\n",
      "basil\n",
      "bean sprouts\n",
      "beans\n",
      "beans and peas\n",
      "beef\n",
      "beef broth/stock/consommé\n",
      "beets\n",
      "berries\n",
      "biscuit or pancake mix\n",
      "biscuits\n",
      "bison\n",
      "black bean sauce\n",
      "black pepper\n",
      "blueberries\n",
      "bok choy\n",
      "bratwurst\n",
      "bread\n",
      "breadcrumbs\n",
      "broccoli and broccoli raab (rapini)\n",
      "broth\n",
      "brussels sprouts\n",
      "buckwheat\n",
      "bulgur\n",
      "butter\n",
      "butter flavor\n",
      "buttermilk\n",
      "cabbage\n",
      "cajun seasoning blend\n",
      "cake, brownie, bread mixes\n",
      "canadian bacon\n",
      "canned chicken\n",
      "canned goods\n",
      "canola oil\n",
      "cantaloupe\n",
      "capers\n",
      "capon\n",
      "carrot juice\n",
      "carrots, parsnips\n",
      "cashew butter\n",
      "cashews\n",
      "casseroles\n",
      "cauliflower\n",
      "caviar\n",
      "celery\n",
      "celery root\n",
      "cereal\n",
      "cereal or granola bars\n",
      "cereal, dry mixes\n",
      "cheese\n",
      "cheese curds\n",
      "cheesecake\n",
      "cherimoya\n",
      "cherries\n",
      "cherry tomatoes\n",
      "chia seeds\n",
      "chicken\n",
      "chicken broth/stock/consommé\n",
      "chicken nuggets, patties\n",
      "chicken parts\n",
      "chicken salad\n",
      "chiffon pies\n",
      "chili powder\n",
      "chives\n",
      "chocolate\n",
      "chocolate hazlenut spread\n",
      "chocolate syrup\n",
      "chorizo\n",
      "chutney\n",
      "cilantro\n",
      "cinnamon\n",
      "cinnamon extract\n",
      "cinnamon rolls\n",
      "citrus fruit\n",
      "cocoa and cocoa mixes\n",
      "coconut\n",
      "coconut cream\n",
      "coconut flavor\n",
      "coconut flour\n",
      "coconut milk\n",
      "coconut oil\n",
      "coconut water\n",
      "coconuts\n",
      "coffee\n",
      "coffee creamer\n",
      "coleslaw\n",
      "commercial brand vacuum-packed dinners\n",
      "commercial bread products\n",
      "commercial cakes and muffins\n",
      "cooked fish\n",
      "cooked pasta\n",
      "cooked poultry dishes\n",
      "cooked rice\n",
      "cooked shellfish\n",
      "cookie dough\n",
      "cookies\n",
      "cooking wine\n",
      "corn on the cob\n",
      "corn syrup\n",
      "corned beef\n",
      "cornish hens\n",
      "cornmeal\n",
      "cornstarch\n",
      "cottage cheese\n",
      "crab legs\n",
      "crab meat\n",
      "crackers\n",
      "cranberries\n",
      "cranberry sauce\n",
      "cream\n",
      "cream cheese\n",
      "cream liquors\n",
      "cream pies\n",
      "cream sauces, milk solids\n",
      "croutons\n",
      "cucumbers\n",
      "cumin\n",
      "dairy filled eclairs\n",
      "dates\n",
      "diet powder mixes and drink mixes\n",
      "dinners\n",
      "dips\n",
      "dough\n",
      "doughnuts\n",
      "dry egg noodles\n",
      "dry gravy mixes\n",
      "dry stuffing mix\n",
      "duck fat\n",
      "duckling\n",
      "edamame\n",
      "egg dishes\n",
      "egg salad\n",
      "egg substitutes\n",
      "eggnog\n",
      "eggplant\n",
      "eggs\n",
      "farro\n",
      "fatty fish\n",
      "fish\n",
      "flavored or herb mixes\n",
      "flaxseed\n",
      "flour\n",
      "formula\n",
      "fresh clams, mussels, oysters\n",
      "fresh lobster tails\n",
      "fresh pasta\n",
      "fresh whole lobster\n",
      "fried chicken\n",
      "frosting or icing\n",
      "frozen entrees\n",
      "frozen potato products\n",
      "frozen pretzels\n",
      "fruit\n",
      "fruit cake\n",
      "fruit cocktail\n",
      "fruit juice in cartons, fruit drinks, punch\n",
      "fruit pies\n",
      "fruit, cut\n",
      "fruits\n",
      "fruits, dried\n",
      "frying oil\n",
      "garam masala\n",
      "garlic\n",
      "garlic powder\n",
      "gelatin\n",
      "ghee\n",
      "giblets\n",
      "ginger root\n",
      "goat\n",
      "goose\n",
      "graham cracker/animal cracker\n",
      "granola\n",
      "grapes\n",
      "grapeseed oil\n",
      "gravy\n",
      "greens\n",
      "grits\n",
      "ground turkey or chicken\n",
      "guacamole\n",
      "guava\n",
      "gummy (fruit) snacks\n",
      "ham\n",
      "ham salad\n",
      "hard liquors\n",
      "herbs\n",
      "herring\n",
      "hoisin sauce\n",
      "honey\n",
      "honeydew\n",
      "horseradish\n",
      "hot dogs\n",
      "hot peppers\n",
      "hot sauce\n",
      "hummus\n",
      "ice cream\n",
      "ice pops\n",
      "instant breakfast drinks\n",
      "jams, jellies, and preserves\n",
      "jars or pouches\n",
      "jerky\n",
      "jicama\n",
      "juice concentrates\n",
      "juice, boxes\n",
      "kale\n",
      "kefir\n",
      "ketchup, cocktail, or chili sauce\n",
      "kimchi\n",
      "kiwi fruit\n",
      "kohlrabi\n",
      "kugel\n",
      "kumquats\n",
      "lamb\n",
      "lean fish\n",
      "leeks\n",
      "leftovers\n",
      "lemon extract\n",
      "lemon juice\n",
      "lemongrass\n",
      "lentils\n",
      "lettuce\n",
      "lime juice\n",
      "liquid concentrate or ready-to-feed formula\n",
      "live clams, mussels, crab, and oysters\n",
      "lobster tails\n",
      "luncheon meat or poultry\n",
      "macadamias\n",
      "macaroons\n",
      "main dishes or meals\n",
      "margarine\n",
      "marinades\n",
      "marinated vegetables\n",
      "marshmallow crème\n",
      "marshmallows\n",
      "mayonnaise\n",
      "meat products\n",
      "meats\n",
      "melons\n",
      "milk\n",
      "millet\n",
      "mint\n",
      "miso\n",
      "molasses\n",
      "muffin\n",
      "mung bean\n",
      "mushrooms\n",
      "mustard\n",
      "nacho cheese\n",
      "nectar\n",
      "nut oils\n",
      "nutmeg\n",
      "nutrition supplement drinks\n",
      "nuts\n",
      "oats\n",
      "oils\n",
      "okra\n",
      "olives\n",
      "onion powder\n",
      "onions\n",
      "orange juice\n",
      "oregano\n",
      "oyster sauce\n",
      "pancakes, waffles\n",
      "papaya, mango, feijoa, passionfruit, casaha melon\n",
      "parsley\n",
      "pasta\n",
      "pasta salad\n",
      "pastrami\n",
      "pastries, danish\n",
      "pate\n",
      "peaches, nectarines, plums, pears, sapote\n",
      "peanut butter\n",
      "peanuts\n",
      "peas\n",
      "pecans\n",
      "pectin\n",
      "peppers\n",
      "pesto\n",
      "pheasant\n",
      "pickles\n",
      "pie crust\n",
      "pies\n",
      "pimento cheese\n",
      "pine nuts\n",
      "pineapple\n",
      "pistachios\n",
      "pitaya/dragon fruit\n",
      "pizza\n",
      "plantains\n",
      "polenta\n",
      "pomegranate\n",
      "popcorn\n",
      "pork\n",
      "pork rinds\n",
      "pork roll\n",
      "potato chips\n",
      "potato salad\n",
      "potatoes\n",
      "poultry pieces\n",
      "powdered milk\n",
      "pretzels\n",
      "prickly pear\n",
      "prosciutto\n",
      "pudding\n",
      "pudding mixes\n",
      "puff pastry\n",
      "pumpkin seeds\n",
      "pumpkins\n",
      "pure vanilla extract\n",
      "quail\n",
      "quark\n",
      "quiche\n",
      "quinoa\n",
      "rabbit\n",
      "radicchio\n",
      "radishes\n",
      "raspberries\n",
      "raw kabobs with vegetables\n",
      "re-hydrated textured soy protein\n",
      "ready-to-bake pie crust\n",
      "red wine\n",
      "refried beans\n",
      "relish\n",
      "retort pouches or boxes\n",
      "rhubarb\n",
      "rice\n",
      "rice milk\n",
      "ricotta\n",
      "roasted nuts (peanuts, cashews, almonds)\n",
      "roasted red peppers\n",
      "rosemary\n",
      "rotisserie chicken\n",
      "rutabagas\n",
      "rye\n",
      "salad dressing\n",
      "salad dressings\n",
      "salami\n",
      "salsa\n",
      "salt\n",
      "sauce mixes\n",
      "sausage\n",
      "sausages\n",
      "scallops\n",
      "seafood\n",
      "seafood salads\n",
      "seasoning blends\n",
      "sesame oil\n",
      "sesame seeds\n",
      "sherbet, sorbet\n",
      "shortening\n",
      "shrimp, crayfish\n",
      "shrimp, shellfish\n",
      "shucked clams, mussels, and oysters\n",
      "soda\n",
      "sorghum\n",
      "soup mixes\n",
      "soup, stews\n",
      "sour cream\n",
      "soy crumbles and hot dogs\n",
      "soy flour\n",
      "soy meat substitutes\n",
      "soy milk\n",
      "soy or rice beverage\n",
      "soy sauce or teriyaki sauce\n",
      "spaghetti sauce\n",
      "spaghetti squash\n",
      "spelt\n",
      "spice/spices\n",
      "squash\n",
      "squid\n",
      "star fruit\n",
      "strawberries\n",
      "string cheese\n",
      "stuffed, raw chicken breasts\n",
      "stuffed, raw pork chops\n",
      "sugar\n",
      "sugar substitutes\n",
      "sun dried tomatoes\n",
      "sunflower oil\n",
      "sunflower seeds\n",
      "surimi seafood\n",
      "swiss chard\n",
      "syrup\n",
      "tahini\n",
      "tamarind\n",
      "tamarind paste\n",
      "tapenade\n",
      "tapiocas\n",
      "taro\n",
      "tea\n",
      "teff\n",
      "tempeh\n",
      "textured soy protein\n",
      "thai red curry paste\n",
      "thyme\n",
      "toaster pastries\n",
      "tofu\n",
      "tomato paste\n",
      "tomato sauce\n",
      "tomatoes\n",
      "tortillas\n",
      "tube cans\n",
      "tuna\n",
      "turducken\n",
      "turkey\n",
      "turkey bacon\n",
      "turkey parts\n",
      "turnips\n",
      "variety meats\n",
      "veal\n",
      "vegan cheddar cheese\n",
      "vegetable juice\n",
      "vegetable oil sprays\n",
      "vegetable soup\n",
      "vegetable stock/broth\n",
      "vegetables\n",
      "venison\n",
      "vinegar\n",
      "walnuts\n",
      "water\n",
      "watermelon\n",
      "whipped cream\n",
      "whipped topping\n",
      "white wine\n",
      "whole wheat bread\n",
      "whole wheat flour\n",
      "worcestershire sauce\n",
      "yams/sweet potatoes\n",
      "yeast\n",
      "yogurt\n",
      "yuca/cassava\n",
      "yuzu\n",
      "yuzu juice\n",
      "zucchini\n"
     ]
    }
   ],
   "source": [
    "foodkeeper = foodKeeperInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data entities:  409\n",
      "Foodkeeper entities:  466\n",
      "Union between foodkeeper and training data: 223\n",
      "Unique training data entities:  186\n",
      "Unique foodkeeper data entities:  243 \n",
      "\n",
      "~~~~~~~~~~~~Only Training~~~~~~~~~~~~\n",
      "0.15\n",
      "2.they\n",
      "4.99\n",
      "699,615,065,551\n",
      "abstract\n",
      "acai\n",
      "acerola\n",
      "activation\n",
      "adored\n",
      "agitating\n",
      "ahora\n",
      "alejandro\n",
      "algae\n",
      "alvarrez\n",
      "approached\n",
      "aslan\n",
      "athletes\n",
      "attracted\n",
      "azul\n",
      "bffs\n",
      "blues\n",
      "bootcamps\n",
      "braves\n",
      "brazils\n",
      "bulborb\n",
      "cafe\n",
      "calamagrostis\n",
      "cameron\n",
      "capricorn\n",
      "capsaicin\n",
      "carafe\n",
      "carbseedling\n",
      "cested\n",
      "chickenbreast\n",
      "chunibyo\n",
      "citeh\n",
      "clashes\n",
      "coconutsㅋㅋㅋ\n",
      "collapse\n",
      "commodified\n",
      "corn‼️\n",
      "coupled\n",
      "creamery\n",
      "cuddling\n",
      "curbside\n",
      "d175\n",
      "dalmunach\n",
      "dani\n",
      "decadent!⁣\n",
      "delusional\n",
      "derwin\n",
      "dinnerly\n",
      "doggos\n",
      "drains\n",
      "dram\n",
      "dranks\n",
      "driveable\n",
      "enrolled\n",
      "erika\n",
      "european\n",
      "exporters\n",
      "extent\n",
      "firewild\n",
      "frickin\n",
      "fuckn\n",
      "gals\n",
      "gasc\n",
      "glenbrook\n",
      "goddddddd\n",
      "goldening\n",
      "grained\n",
      "grann\n",
      "griswald\n",
      "gulf\n",
      "hachinohe\n",
      "hamin\n",
      "hank\n",
      "hauck\n",
      "helga\n",
      "hibby\n",
      "hocking\n",
      "howd\n",
      "iffco\n",
      "indians\n",
      "insects\n",
      "karedok\n",
      "kiddush\n",
      "kiita\n",
      "kirkby\n",
      "knabe\n",
      "krogan\n",
      "latino\n",
      "libya\n",
      "lindsay\n",
      "lure\n",
      "mach\n",
      "malnourished\n",
      "marathi\n",
      "matos\n",
      "mcfarlane\n",
      "melville\n",
      "mercadona\n",
      "miyuki\n",
      "montgomery\n",
      "monuments\n",
      "morphological\n",
      "mothballs\n",
      "murderous\n",
      "murgor\n",
      "nairobi\n",
      "nazis\n",
      "nebraska\n",
      "nicca\n",
      "nintendo\n",
      "odor\n",
      "orridge\n",
      "outsource\n",
      "overlook\n",
      "overtake\n",
      "parlour\n",
      "patreon\n",
      "patron\n",
      "patterns\n",
      "petite\n",
      "pharmacist\n",
      "plateful\n",
      "plead\n",
      "pleeeease\n",
      "polishes\n",
      "pretended\n",
      "psychopaths\n",
      "quests\n",
      "radiance\n",
      "ramsey\n",
      "ras\n",
      "reconstituted\n",
      "relleno\n",
      "remastered\n",
      "resume\n",
      "risottos\n",
      "rockpalast\n",
      "ronni\n",
      "roobee\n",
      "saag\n",
      "sally\n",
      "screening\n",
      "sculpt\n",
      "shadiyon\n",
      "sheikh\n",
      "shelters\n",
      "showcases\n",
      "skinning\n",
      "skippy\n",
      "slammed\n",
      "snort\n",
      "snub\n",
      "solitude\n",
      "stanton\n",
      "striker\n",
      "stutzle\n",
      "subdued\n",
      "svelte\n",
      "syahleka\n",
      "throwback\n",
      "toledo\n",
      "tonnes\n",
      "torah\n",
      "tournament\n",
      "trimmings\n",
      "trop\n",
      "twewy\n",
      "ummmmmm\n",
      "undead\n",
      "unexpected\n",
      "urged\n",
      "vardy\n",
      "vibrate\n",
      "victoria\n",
      "wales\n",
      "welby\n",
      "whitewater\n",
      "wholly\n",
      "woolfardisworthy\n",
      "فوغا\n",
      "↪\n",
      "ㅋㅋㅋㅋmother\n",
      "~~~~~~~~~~~~Only Foodkeeper~~~~~~~~~~~~\n",
      "\"genuine\" maple syrup\n",
      "almond butter\n",
      "almond extract\n",
      "almond milk\n",
      "almond oil\n",
      "almonds\n",
      "apple cider\n",
      "apple cider vinegar\n",
      "apple juice\n",
      "artichokes, whole\n",
      "avocado oil\n",
      "baby carrots\n",
      "bacon bits\n",
      "bacon grease\n",
      "bagged greens\n",
      "baking powder\n",
      "baking soda\n",
      "balsamic vinegar\n",
      "bamboo shoots\n",
      "barbecue sauce\n",
      "bean sprouts\n",
      "beans and peas\n",
      "beef broth/stock/consommé\n",
      "biscuit or pancake mix\n",
      "black bean sauce\n",
      "black pepper\n",
      "bok choy\n",
      "broccoli and broccoli raab (rapini)\n",
      "brussels sprouts\n",
      "butter flavor\n",
      "cajun seasoning blend\n",
      "cake, brownie, bread mixes\n",
      "canadian bacon\n",
      "canned chicken\n",
      "canned goods\n",
      "canola oil\n",
      "carrot juice\n",
      "carrots, parsnips\n",
      "cashew butter\n",
      "celery root\n",
      "cereal or granola bars\n",
      "cereal, dry mixes\n",
      "cheese curds\n",
      "cherry tomatoes\n",
      "chia seeds\n",
      "chicken broth/stock/consommé\n",
      "chicken nuggets, patties\n",
      "chicken parts\n",
      "chicken salad\n",
      "chiffon pies\n",
      "chili powder\n",
      "chocolate hazlenut spread\n",
      "chocolate syrup\n",
      "cinnamon extract\n",
      "cinnamon rolls\n",
      "citrus fruit\n",
      "cocoa and cocoa mixes\n",
      "coconut cream\n",
      "coconut flavor\n",
      "coconut flour\n",
      "coconut milk\n",
      "coconut oil\n",
      "coconut water\n",
      "coffee creamer\n",
      "commercial brand vacuum-packed dinners\n",
      "commercial bread products\n",
      "commercial cakes and muffins\n",
      "cooked fish\n",
      "cooked pasta\n",
      "cooked poultry dishes\n",
      "cooked rice\n",
      "cooked shellfish\n",
      "cookie dough\n",
      "cooking wine\n",
      "corn on the cob\n",
      "corn syrup\n",
      "corned beef\n",
      "cornish hens\n",
      "cottage cheese\n",
      "crab legs\n",
      "crab meat\n",
      "cranberry sauce\n",
      "cream cheese\n",
      "cream liquors\n",
      "cream pies\n",
      "cream sauces, milk solids\n",
      "dairy filled eclairs\n",
      "diet powder mixes and drink mixes\n",
      "dry egg noodles\n",
      "dry gravy mixes\n",
      "dry stuffing mix\n",
      "duck fat\n",
      "egg dishes\n",
      "egg salad\n",
      "egg substitutes\n",
      "fatty fish\n",
      "flavored or herb mixes\n",
      "fresh clams, mussels, oysters\n",
      "fresh lobster tails\n",
      "fresh pasta\n",
      "fresh whole lobster\n",
      "fried chicken\n",
      "frosting or icing\n",
      "frozen entrees\n",
      "frozen potato products\n",
      "frozen pretzels\n",
      "fruit cake\n",
      "fruit cocktail\n",
      "fruit juice in cartons, fruit drinks, punch\n",
      "fruit pies\n",
      "fruit, cut\n",
      "fruits, dried\n",
      "frying oil\n",
      "garam masala\n",
      "garlic powder\n",
      "ginger root\n",
      "graham cracker/animal cracker\n",
      "grapeseed oil\n",
      "ground turkey or chicken\n",
      "gummy (fruit) snacks\n",
      "ham salad\n",
      "hard liquors\n",
      "hoisin sauce\n",
      "hot dogs\n",
      "hot peppers\n",
      "hot sauce\n",
      "ice cream\n",
      "ice pops\n",
      "instant breakfast drinks\n",
      "jams, jellies, and preserves\n",
      "jars or pouches\n",
      "juice concentrates\n",
      "juice, boxes\n",
      "ketchup, cocktail, or chili sauce\n",
      "kiwi fruit\n",
      "lean fish\n",
      "lemon extract\n",
      "lemon juice\n",
      "lime juice\n",
      "liquid concentrate or ready-to-feed formula\n",
      "live clams, mussels, crab, and oysters\n",
      "lobster tails\n",
      "luncheon meat or poultry\n",
      "main dishes or meals\n",
      "marinated vegetables\n",
      "marshmallow crème\n",
      "meat products\n",
      "mung bean\n",
      "nacho cheese\n",
      "nut oils\n",
      "nutrition supplement drinks\n",
      "onion powder\n",
      "orange juice\n",
      "oyster sauce\n",
      "pancakes, waffles\n",
      "papaya, mango, feijoa, passionfruit, casaha melon\n",
      "pasta salad\n",
      "pastries, danish\n",
      "peaches, nectarines, plums, pears, sapote\n",
      "peanut butter\n",
      "pie crust\n",
      "pimento cheese\n",
      "pine nuts\n",
      "pitaya/dragon fruit\n",
      "pork rinds\n",
      "pork roll\n",
      "potato chips\n",
      "potato salad\n",
      "poultry pieces\n",
      "powdered milk\n",
      "prickly pear\n",
      "pudding mixes\n",
      "puff pastry\n",
      "pumpkin seeds\n",
      "pure vanilla extract\n",
      "raw kabobs with vegetables\n",
      "re-hydrated textured soy protein\n",
      "ready-to-bake pie crust\n",
      "red wine\n",
      "refried beans\n",
      "retort pouches or boxes\n",
      "rice milk\n",
      "roasted nuts (peanuts, cashews, almonds)\n",
      "roasted red peppers\n",
      "rotisserie chicken\n",
      "salad dressing\n",
      "salad dressings\n",
      "salami\n",
      "sauce mixes\n",
      "seafood salads\n",
      "seasoning blends\n",
      "sesame oil\n",
      "sesame seeds\n",
      "sherbet, sorbet\n",
      "shrimp, crayfish\n",
      "shrimp, shellfish\n",
      "shucked clams, mussels, and oysters\n",
      "soup mixes\n",
      "soup, stews\n",
      "sour cream\n",
      "soy crumbles and hot dogs\n",
      "soy flour\n",
      "soy meat substitutes\n",
      "soy milk\n",
      "soy or rice beverage\n",
      "soy sauce or teriyaki sauce\n",
      "spaghetti sauce\n",
      "spaghetti squash\n",
      "spice/spices\n",
      "star fruit\n",
      "string cheese\n",
      "stuffed, raw chicken breasts\n",
      "stuffed, raw pork chops\n",
      "sugar substitutes\n",
      "sun dried tomatoes\n",
      "sunflower oil\n",
      "sunflower seeds\n",
      "surimi seafood\n",
      "swiss chard\n",
      "tamarind paste\n",
      "textured soy protein\n",
      "thai red curry paste\n",
      "toaster pastries\n",
      "tomato paste\n",
      "tomato sauce\n",
      "tube cans\n",
      "turkey bacon\n",
      "turkey parts\n",
      "variety meats\n",
      "vegan cheddar cheese\n",
      "vegetable juice\n",
      "vegetable oil sprays\n",
      "vegetable soup\n",
      "vegetable stock/broth\n",
      "whipped cream\n",
      "whipped topping\n",
      "white wine\n",
      "whole wheat bread\n",
      "whole wheat flour\n",
      "worcestershire sauce\n",
      "yams/sweet potatoes\n",
      "yuca/cassava\n",
      "yuzu juice\n"
     ]
    }
   ],
   "source": [
    "##     Information about the different datasets\n",
    "x = list(myTrainingdata)\n",
    "\n",
    "print(\"Training data entities: \",len(x))\n",
    "print(\"Foodkeeper entities: \", len(foodkeeper))\n",
    "\n",
    "\n",
    "diff = list(set(x) & set(foodkeeper))\n",
    "print(\"Union between foodkeeper and training data: \" + str(len(diff)))\n",
    "#for elem in sorted(diff):\n",
    "    #print(elem)\n",
    "\n",
    "onlyTraining = list(set(x) - set(foodkeeper))\n",
    "onlyFoodkeeper = list(set(foodkeeper) - set(x))\n",
    "\n",
    "        \n",
    "print(\"Unique training data entities: \", len(onlyTraining))\n",
    "print(\"Unique foodkeeper data entities: \",len(onlyFoodkeeper), '\\n')\n",
    "\n",
    "print(\"~~~~~~~~~~~~Only Training~~~~~~~~~~~~\")\n",
    "for element in sorted(onlyTraining):\n",
    "    print(element)\n",
    "\n",
    "print(\"~~~~~~~~~~~~Only Foodkeeper~~~~~~~~~~~~\")\n",
    "for element in sorted(onlyFoodkeeper):\n",
    "    print(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~0~~~~~~~~~~~~~~~~~\n",
      "Total keywords:  15\n",
      "Total Tweets:  0\n",
      "List of Keywords:\n",
      "\n",
      " ['cheese', 'chicken', 'milk', 'cream', 'butter', 'fruit', 'rice', 'water', 'bread', 'garlic', 'chocolate', 'sugar', 'coconut', 'fish', 'pasta'] \n",
      "\n",
      "\n",
      "~~~~~~~~~~~~~~~~~1~~~~~~~~~~~~~~~~~\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:00<00:00, 230.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n",
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'ner']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
      "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  ------------  --------  ------  ------  ------  ------\n",
      "  0       0          0.00     37.50    2.73    3.25    2.35    0.03\n",
      "  8     200         76.88    785.50   99.71  100.00   99.41    1.00\n",
      " 20     400         24.19     16.43  100.00  100.00  100.00    1.00\n",
      " 34     600         10.56      4.35  100.00  100.00  100.00    1.00\n",
      " 52     800         11.54      3.25  100.00  100.00  100.00    1.00\n",
      " 75    1000         65.62     15.45  100.00  100.00  100.00    1.00\n",
      "103    1200         93.35     19.12  100.00  100.00  100.00    1.00\n",
      "137    1400         20.58      4.05  100.00  100.00  100.00    1.00\n",
      "179    1600          0.12      0.02  100.00  100.00  100.00    1.00\n",
      "229    1800          0.00      0.00  100.00  100.00  100.00    1.00\n",
      "293    2000        147.76     24.31  100.00  100.00  100.00    1.00\n",
      "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
      "output/model-last\n",
      "\n",
      "Total keywords:  15\n",
      "List of Keywords:\n",
      "\n",
      " ['cheese', 'chicken', 'milk', 'cream', 'butter', 'fruit', 'rice', 'water', 'bread', 'garlic', 'chocolate', 'sugar', 'coconut', 'fish', 'pasta'] \n",
      "\n",
      "\n",
      "[[ 9 35]\n",
      " [ 1 38]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.90      0.20      0.33        44\n",
      "           0       0.52      0.97      0.68        39\n",
      "\n",
      "    accuracy                           0.57        83\n",
      "   macro avg       0.71      0.59      0.51        83\n",
      "weighted avg       0.72      0.57      0.50        83\n",
      "\n",
      "Total keywords:  37\n",
      "Total Tweets:  42\n",
      "List of Keywords:\n",
      "\n",
      " ['cheese', 'chicken', 'milk', 'cream', 'butter', 'fruit', 'rice', 'water', 'bread', 'garlic', 'chocolate', 'sugar', 'coconut', 'fish', 'pasta', 'yogurt', 'pork', 'eggs', 'vegetables', 'cauliflower', 'nuts', 'cereal', 'potatoes', 'oats', 'cheesecake', 'crackers', 'cinnamon', 'muffin', 'goat', 'pesto', 'vinegar', 'honey', 'peanuts', 'oregano', 'flour', 'dough', 'aioli'] \n",
      "\n",
      "\n",
      "~~~~~~~~~~~~~~~~~2~~~~~~~~~~~~~~~~~\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 32/947 [00:00<00:02, 314.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n",
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 88/947 [00:00<00:04, 192.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n",
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 126/947 [00:00<00:05, 142.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 154/947 [00:01<00:06, 113.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▊        | 177/947 [00:01<00:08, 94.50it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 235/947 [00:02<00:11, 63.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 320/947 [00:04<00:14, 43.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 355/947 [00:04<00:14, 40.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▊      | 365/947 [00:05<00:14, 40.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 375/947 [00:05<00:14, 39.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 516/947 [00:09<00:15, 27.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 947/947 [00:31<00:00, 30.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'ner']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
      "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  ------------  --------  ------  ------  ------  ------\n",
      "  0       0          0.00     16.50    0.00    0.00    0.00    0.00\n",
      "  0     200         51.33   1198.94   87.97   80.47   97.01    0.88\n",
      "  0     400         29.62    599.49   86.72   82.42   91.50    0.87\n",
      "  1     600         30.77    591.21   91.60   89.66   93.63    0.92\n",
      "  2     800         36.34    574.10   94.87   92.86   96.96    0.95\n",
      "  3    1000         66.31    447.35   96.78   94.69   98.96    0.97\n",
      "  4    1200        120.12    406.61   98.40   98.40   98.40    0.98\n",
      "  6    1400        174.32    275.72   99.13   99.48   98.79    0.99\n",
      "  8    1600        231.92    204.95   99.63   99.35   99.91    1.00\n",
      " 10    1800        250.69    153.98   99.65   99.31  100.00    1.00\n",
      " 13    2000        376.12    137.31   99.63  100.00   99.26    1.00\n",
      " 17    2200        350.85     93.56  100.00  100.00  100.00    1.00\n",
      " 21    2400        373.81     95.74   99.98   99.96  100.00    1.00\n",
      " 26    2600        278.62     68.18  100.00  100.00  100.00    1.00\n",
      " 30    2800        202.41     36.98  100.00  100.00  100.00    1.00\n",
      " 35    3000        352.13     47.38  100.00  100.00  100.00    1.00\n",
      " 40    3200        397.83     76.49   99.96   99.96   99.96    1.00\n",
      " 44    3400        345.32     82.63   99.98  100.00   99.96    1.00\n",
      " 49    3600        231.41     56.89   99.98   99.96  100.00    1.00\n",
      " 53    3800        191.29     33.68  100.00  100.00  100.00    1.00\n",
      "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
      "output/model-last\n",
      "\n",
      "Total keywords:  37\n",
      "List of Keywords:\n",
      "\n",
      " ['cheese', 'chicken', 'milk', 'cream', 'butter', 'fruit', 'rice', 'water', 'bread', 'garlic', 'chocolate', 'sugar', 'coconut', 'fish', 'pasta', 'yogurt', 'pork', 'eggs', 'vegetables', 'cauliflower', 'nuts', 'cereal', 'potatoes', 'oats', 'cheesecake', 'crackers', 'cinnamon', 'muffin', 'goat', 'pesto', 'vinegar', 'honey', 'peanuts', 'oregano', 'flour', 'dough', 'aioli'] \n",
      "\n",
      "\n",
      "[[12 32]\n",
      " [ 0 39]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.27      0.43        44\n",
      "           0       0.55      1.00      0.71        39\n",
      "\n",
      "    accuracy                           0.61        83\n",
      "   macro avg       0.77      0.64      0.57        83\n",
      "weighted avg       0.79      0.61      0.56        83\n",
      "\n",
      "Total keywords:  193\n",
      "Total Tweets:  947\n",
      "List of Keywords:\n",
      "\n",
      " ['cheese', 'chicken', 'milk', 'cream', 'butter', 'fruit', 'rice', 'water', 'bread', 'garlic', 'chocolate', 'sugar', 'coconut', 'fish', 'pasta', 'yogurt', 'pork', 'eggs', 'vegetables', 'cauliflower', 'nuts', 'cereal', 'potatoes', 'oats', 'cheesecake', 'crackers', 'cinnamon', 'muffin', 'goat', 'pesto', 'vinegar', 'honey', 'peanuts', 'oregano', 'flour', 'dough', 'aioli', 'buttermilk', 'coffee', 'syrup', 'tomatoes', 'bagel', 'blueberries', 'herbs', 'sausage', 'mushrooms', 'kale', 'celery', 'beans', 'soda', 'beef', 'tofu', 'base', 'onions', 'quinoa', 'margarine', 'oils', 'salt', 'walnuts', 'pudding', 'quiche', 'ricotta', 'strawberries', 'peas', 'bananas', 'arugula', 'beets', 'veal', 'meats', 'pineapple', 'olives', 'rabbit', 'fruits', 'granola', 'bacon', 'gravy', 'turkey', 'biscuits', 'parsley', 'basil', 'watermelon', 'quail', 'tuna', 'peppers', 'rosemary', 'lettuce', 'apples', 'tea', 'berries', 'avocados', 'pickles', 'kimchi', 'dates', 'scallops', 'yuzu', 'zucchini', 'cumin', 'lamb', 'miso', 'spelt', 'barley', 'popcorn', 'salsa', 'asparagus', 'broth', 'tortillas', 'pistachios', 'ghee', 'guacamole', 'cilantro', 'sausages', 'pate', 'leftovers', 'casseroles', 'cookies', 'doughnuts', 'guava', 'polenta', 'pies', 'ham', 'nutmeg', 'yeast', 'raspberries', 'cornmeal', 'cornstarch', 'grits', 'mustard', 'tamarind', 'cabbage', 'nectar', 'mint', 'greens', 'apricots', 'squash', 'cherimoya', 'grapes', 'coconuts', 'almonds', 'melons', 'pomegranate', 'thyme', 'eggplant', 'lentils', 'turnips', 'leeks', 'radishes', 'taro', 'cucumbers', 'pizza', 'hummus', 'pretzels', 'tempeh', 'pecans', 'flaxseed', 'horseradish', 'marinades', 'coleslaw', 'marshmallows', 'pectin', 'squid', 'kumquats', 'tahini', 'cherries', 'salami', 'macadamias', 'cashews', 'rye', 'rhubarb', 'formula', 'seafood', 'jicama', 'kohlrabi', 'honeydew', 'tapenade', 'chives', 'jerky', 'molasses', 'macaroons', 'plantains', 'caviar', 'buckwheat', 'farro', 'millet', 'teff', 'capers', 'mayonnaise', 'prosciutto', 'chorizo', 'bulgur', 'edamame', 'breadcrumbs', 'anchovies', 'radicchio'] \n",
      "\n",
      "\n",
      "~~~~~~~~~~~~~~~~~3~~~~~~~~~~~~~~~~~\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 38/1019 [00:00<00:02, 376.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n",
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 103/1019 [00:00<00:04, 186.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n",
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▏        | 124/1019 [00:00<00:05, 150.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n",
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 155/1019 [00:01<00:07, 114.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 179/1019 [00:01<00:09, 93.28it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 214/1019 [00:01<00:11, 69.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 254/1019 [00:02<00:13, 54.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 281/1019 [00:03<00:15, 47.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 296/1019 [00:03<00:16, 44.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 336/1019 [00:04<00:16, 42.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 353/1019 [00:05<00:17, 38.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▊      | 393/1019 [00:06<00:17, 35.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 401/1019 [00:06<00:18, 32.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 413/1019 [00:06<00:18, 32.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 449/1019 [00:08<00:17, 31.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 559/1019 [00:11<00:18, 24.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 655/1019 [00:15<00:15, 23.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 769/1019 [00:21<00:12, 20.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 1018/1019 [00:36<00:00, 14.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1019/1019 [00:36<00:00, 28.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'ner']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
      "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  ------------  --------  ------  ------  ------  ------\n",
      "  0       0          0.00     37.17    0.00    0.00    0.00    0.00\n",
      "  0     200         69.13   1828.68   86.76   79.91   94.90    0.87\n",
      "  0     400         30.82    968.43   89.44   84.22   95.35    0.89\n",
      "  1     600         26.56    945.64   90.77   85.03   97.35    0.91\n",
      "  2     800         34.03   1020.83   92.14   92.71   91.57    0.92\n",
      "  3    1000         49.88    949.19   95.88   94.88   96.89    0.96\n",
      "  4    1200         74.18    763.94   97.52   96.86   98.19    0.98\n",
      "  5    1400         98.96    625.26   98.62   97.73   99.52    0.99\n",
      "  7    1600        140.15    493.52   99.11   98.92   99.30    0.99\n",
      " 10    1800        201.91    422.95   99.60   99.52   99.69    1.00\n",
      " 12    2000        287.79    345.85   99.80   99.76   99.83    1.00\n",
      " 16    2200        268.73    278.94   99.84   99.81   99.88    1.00\n",
      " 20    2400        385.41    283.56   99.77   99.83   99.71    1.00\n",
      " 24    2600        394.50    227.14   99.90   99.86   99.95    1.00\n",
      " 28    2800        416.52    211.58   99.90   99.88   99.93    1.00\n",
      " 33    3000        465.51    200.46   99.89   99.81   99.98    1.00\n",
      " 37    3200        451.30    184.08   99.81   99.95   99.66    1.00\n",
      " 41    3400        383.28    153.88   99.92   99.83  100.00    1.00\n",
      " 45    3600        395.54    150.38   99.87   99.74  100.00    1.00\n",
      " 50    3800        456.93    147.92   99.92   99.86   99.98    1.00\n",
      " 54    4000        373.42    114.22   99.92   99.86   99.98    1.00\n",
      " 58    4200        382.39    122.84   99.78  100.00   99.57    1.00\n",
      " 62    4400        348.53    125.71   99.89   99.81   99.98    1.00\n",
      " 67    4600        449.52    136.02   99.92  100.00   99.83    1.00\n",
      " 71    4800        429.23    106.15   99.92   99.98   99.86    1.00\n",
      " 75    5000        425.91    104.02   99.92   99.88   99.95    1.00\n",
      "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
      "output/model-last\n",
      "\n",
      "Total keywords:  193\n",
      "List of Keywords:\n",
      "\n",
      " ['cheese', 'chicken', 'milk', 'cream', 'butter', 'fruit', 'rice', 'water', 'bread', 'garlic', 'chocolate', 'sugar', 'coconut', 'fish', 'pasta', 'yogurt', 'pork', 'eggs', 'vegetables', 'cauliflower', 'nuts', 'cereal', 'potatoes', 'oats', 'cheesecake', 'crackers', 'cinnamon', 'muffin', 'goat', 'pesto', 'vinegar', 'honey', 'peanuts', 'oregano', 'flour', 'dough', 'aioli', 'buttermilk', 'coffee', 'syrup', 'tomatoes', 'bagel', 'blueberries', 'herbs', 'sausage', 'mushrooms', 'kale', 'celery', 'beans', 'soda', 'beef', 'tofu', 'base', 'onions', 'quinoa', 'margarine', 'oils', 'salt', 'walnuts', 'pudding', 'quiche', 'ricotta', 'strawberries', 'peas', 'bananas', 'arugula', 'beets', 'veal', 'meats', 'pineapple', 'olives', 'rabbit', 'fruits', 'granola', 'bacon', 'gravy', 'turkey', 'biscuits', 'parsley', 'basil', 'watermelon', 'quail', 'tuna', 'peppers', 'rosemary', 'lettuce', 'apples', 'tea', 'berries', 'avocados', 'pickles', 'kimchi', 'dates', 'scallops', 'yuzu', 'zucchini', 'cumin', 'lamb', 'miso', 'spelt', 'barley', 'popcorn', 'salsa', 'asparagus', 'broth', 'tortillas', 'pistachios', 'ghee', 'guacamole', 'cilantro', 'sausages', 'pate', 'leftovers', 'casseroles', 'cookies', 'doughnuts', 'guava', 'polenta', 'pies', 'ham', 'nutmeg', 'yeast', 'raspberries', 'cornmeal', 'cornstarch', 'grits', 'mustard', 'tamarind', 'cabbage', 'nectar', 'mint', 'greens', 'apricots', 'squash', 'cherimoya', 'grapes', 'coconuts', 'almonds', 'melons', 'pomegranate', 'thyme', 'eggplant', 'lentils', 'turnips', 'leeks', 'radishes', 'taro', 'cucumbers', 'pizza', 'hummus', 'pretzels', 'tempeh', 'pecans', 'flaxseed', 'horseradish', 'marinades', 'coleslaw', 'marshmallows', 'pectin', 'squid', 'kumquats', 'tahini', 'cherries', 'salami', 'macadamias', 'cashews', 'rye', 'rhubarb', 'formula', 'seafood', 'jicama', 'kohlrabi', 'honeydew', 'tapenade', 'chives', 'jerky', 'molasses', 'macaroons', 'plantains', 'caviar', 'buckwheat', 'farro', 'millet', 'teff', 'capers', 'mayonnaise', 'prosciutto', 'chorizo', 'bulgur', 'edamame', 'breadcrumbs', 'anchovies', 'radicchio'] \n",
      "\n",
      "\n",
      "[[26 18]\n",
      " [ 4 35]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.87      0.59      0.70        44\n",
      "           0       0.66      0.90      0.76        39\n",
      "\n",
      "    accuracy                           0.73        83\n",
      "   macro avg       0.76      0.74      0.73        83\n",
      "weighted avg       0.77      0.73      0.73        83\n",
      "\n",
      "Total keywords:  195\n",
      "Total Tweets:  1019\n",
      "List of Keywords:\n",
      "\n",
      " ['cheese', 'chicken', 'milk', 'cream', 'butter', 'fruit', 'rice', 'water', 'bread', 'garlic', 'chocolate', 'sugar', 'coconut', 'fish', 'pasta', 'yogurt', 'pork', 'eggs', 'vegetables', 'cauliflower', 'nuts', 'cereal', 'potatoes', 'oats', 'cheesecake', 'crackers', 'cinnamon', 'muffin', 'goat', 'pesto', 'vinegar', 'honey', 'peanuts', 'oregano', 'flour', 'dough', 'aioli', 'buttermilk', 'coffee', 'syrup', 'tomatoes', 'bagel', 'blueberries', 'herbs', 'sausage', 'mushrooms', 'kale', 'celery', 'beans', 'soda', 'beef', 'tofu', 'base', 'onions', 'quinoa', 'margarine', 'oils', 'salt', 'walnuts', 'pudding', 'quiche', 'ricotta', 'strawberries', 'peas', 'bananas', 'arugula', 'beets', 'veal', 'meats', 'pineapple', 'olives', 'rabbit', 'fruits', 'granola', 'bacon', 'gravy', 'turkey', 'biscuits', 'parsley', 'basil', 'watermelon', 'quail', 'tuna', 'peppers', 'rosemary', 'lettuce', 'apples', 'tea', 'berries', 'avocados', 'pickles', 'kimchi', 'dates', 'scallops', 'yuzu', 'zucchini', 'cumin', 'lamb', 'miso', 'spelt', 'barley', 'popcorn', 'salsa', 'asparagus', 'broth', 'tortillas', 'pistachios', 'ghee', 'guacamole', 'cilantro', 'sausages', 'pate', 'leftovers', 'casseroles', 'cookies', 'doughnuts', 'guava', 'polenta', 'pies', 'ham', 'nutmeg', 'yeast', 'raspberries', 'cornmeal', 'cornstarch', 'grits', 'mustard', 'tamarind', 'cabbage', 'nectar', 'mint', 'greens', 'apricots', 'squash', 'cherimoya', 'grapes', 'coconuts', 'almonds', 'melons', 'pomegranate', 'thyme', 'eggplant', 'lentils', 'turnips', 'leeks', 'radishes', 'taro', 'cucumbers', 'pizza', 'hummus', 'pretzels', 'tempeh', 'pecans', 'flaxseed', 'horseradish', 'marinades', 'coleslaw', 'marshmallows', 'pectin', 'squid', 'kumquats', 'tahini', 'cherries', 'salami', 'macadamias', 'cashews', 'rye', 'rhubarb', 'formula', 'seafood', 'jicama', 'kohlrabi', 'honeydew', 'tapenade', 'chives', 'jerky', 'molasses', 'macaroons', 'plantains', 'caviar', 'buckwheat', 'farro', 'millet', 'teff', 'capers', 'mayonnaise', 'prosciutto', 'chorizo', 'bulgur', 'edamame', 'breadcrumbs', 'anchovies', 'radicchio', 'croutons', 'pumpkins'] \n",
      "\n",
      "\n",
      "~~~~~~~~~~~~~~~~~4~~~~~~~~~~~~~~~~~\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 30/1019 [00:00<00:03, 290.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n",
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 103/1019 [00:00<00:05, 160.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n",
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▏        | 120/1019 [00:00<00:07, 122.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n",
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 157/1019 [00:01<00:09, 91.15it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 184/1019 [00:01<00:11, 71.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 213/1019 [00:02<00:13, 59.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 255/1019 [00:03<00:15, 50.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 277/1019 [00:03<00:16, 45.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 297/1019 [00:04<00:16, 43.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 336/1019 [00:05<00:17, 38.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 352/1019 [00:05<00:18, 35.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▊      | 393/1019 [00:06<00:18, 33.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 401/1019 [00:06<00:18, 33.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 413/1019 [00:07<00:18, 33.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 449/1019 [00:08<00:17, 32.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 559/1019 [00:12<00:17, 25.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 655/1019 [00:16<00:16, 21.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 769/1019 [00:21<00:12, 20.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1019/1019 [00:37<00:00, 27.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'ner']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
      "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  ------------  --------  ------  ------  ------  ------\n",
      "  0       0          0.00     37.17    0.00    0.00    0.00    0.00\n",
      "  0     200         69.13   1828.68   86.74   79.91   94.85    0.87\n",
      "  0     400         31.57    969.82   88.93   83.89   94.61    0.89\n",
      "  1     600         28.28    961.17   91.09   85.70   97.21    0.91\n",
      "  2     800         33.85   1032.25   91.73   92.53   90.95    0.92\n",
      "  3    1000         50.12    924.93   95.63   95.75   95.50    0.96\n",
      "  4    1200         77.76    758.99   97.49   96.49   98.51    0.97\n",
      "  5    1400        107.86    620.78   99.18   98.88   99.49    0.99\n",
      "  7    1600        150.71    466.47   99.28   98.99   99.57    0.99\n",
      " 10    1800        213.34    400.21   99.63   99.38   99.88    1.00\n",
      " 12    2000        289.60    319.86   99.81   99.78   99.83    1.00\n",
      " 16    2200        361.76    294.60   99.82   99.86   99.78    1.00\n",
      " 20    2400        400.86    297.75   99.87   99.76   99.98    1.00\n",
      " 24    2600        422.94    216.60   99.86   99.76   99.95    1.00\n",
      " 28    2800        490.68    206.33   99.90   99.83   99.98    1.00\n",
      " 33    3000        468.86    216.78   99.81   99.90   99.71    1.00\n",
      " 37    3200        438.97    199.87   99.90   99.88   99.93    1.00\n",
      " 41    3400        360.24    158.85   99.92   99.83  100.00    1.00\n",
      " 45    3600        378.34    131.59   99.90   99.86   99.95    1.00\n",
      " 50    3800        447.33    148.67   99.89   99.95   99.83    1.00\n",
      " 54    4000        495.43    149.28   99.90   99.81  100.00    1.00\n",
      " 58    4200        359.63    130.50   99.92   99.88   99.95    1.00\n",
      " 62    4400        564.57    153.27   99.89   99.86   99.93    1.00\n",
      " 67    4600        342.44    120.49   99.86  100.00   99.71    1.00\n",
      " 71    4800        379.13    122.25   99.92   99.88   99.95    1.00\n",
      " 75    5000        304.33    102.71   99.92   99.88   99.95    1.00\n",
      "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
      "output/model-last\n",
      "\n",
      "Total keywords:  195\n",
      "List of Keywords:\n",
      "\n",
      " ['cheese', 'chicken', 'milk', 'cream', 'butter', 'fruit', 'rice', 'water', 'bread', 'garlic', 'chocolate', 'sugar', 'coconut', 'fish', 'pasta', 'yogurt', 'pork', 'eggs', 'vegetables', 'cauliflower', 'nuts', 'cereal', 'potatoes', 'oats', 'cheesecake', 'crackers', 'cinnamon', 'muffin', 'goat', 'pesto', 'vinegar', 'honey', 'peanuts', 'oregano', 'flour', 'dough', 'aioli', 'buttermilk', 'coffee', 'syrup', 'tomatoes', 'bagel', 'blueberries', 'herbs', 'sausage', 'mushrooms', 'kale', 'celery', 'beans', 'soda', 'beef', 'tofu', 'base', 'onions', 'quinoa', 'margarine', 'oils', 'salt', 'walnuts', 'pudding', 'quiche', 'ricotta', 'strawberries', 'peas', 'bananas', 'arugula', 'beets', 'veal', 'meats', 'pineapple', 'olives', 'rabbit', 'fruits', 'granola', 'bacon', 'gravy', 'turkey', 'biscuits', 'parsley', 'basil', 'watermelon', 'quail', 'tuna', 'peppers', 'rosemary', 'lettuce', 'apples', 'tea', 'berries', 'avocados', 'pickles', 'kimchi', 'dates', 'scallops', 'yuzu', 'zucchini', 'cumin', 'lamb', 'miso', 'spelt', 'barley', 'popcorn', 'salsa', 'asparagus', 'broth', 'tortillas', 'pistachios', 'ghee', 'guacamole', 'cilantro', 'sausages', 'pate', 'leftovers', 'casseroles', 'cookies', 'doughnuts', 'guava', 'polenta', 'pies', 'ham', 'nutmeg', 'yeast', 'raspberries', 'cornmeal', 'cornstarch', 'grits', 'mustard', 'tamarind', 'cabbage', 'nectar', 'mint', 'greens', 'apricots', 'squash', 'cherimoya', 'grapes', 'coconuts', 'almonds', 'melons', 'pomegranate', 'thyme', 'eggplant', 'lentils', 'turnips', 'leeks', 'radishes', 'taro', 'cucumbers', 'pizza', 'hummus', 'pretzels', 'tempeh', 'pecans', 'flaxseed', 'horseradish', 'marinades', 'coleslaw', 'marshmallows', 'pectin', 'squid', 'kumquats', 'tahini', 'cherries', 'salami', 'macadamias', 'cashews', 'rye', 'rhubarb', 'formula', 'seafood', 'jicama', 'kohlrabi', 'honeydew', 'tapenade', 'chives', 'jerky', 'molasses', 'macaroons', 'plantains', 'caviar', 'buckwheat', 'farro', 'millet', 'teff', 'capers', 'mayonnaise', 'prosciutto', 'chorizo', 'bulgur', 'edamame', 'breadcrumbs', 'anchovies', 'radicchio', 'croutons', 'pumpkins'] \n",
      "\n",
      "\n",
      "Decreasing entityCheckCount variable by 1\n",
      "[[22 22]\n",
      " [ 4 35]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.85      0.50      0.63        44\n",
      "           0       0.61      0.90      0.73        39\n",
      "\n",
      "    accuracy                           0.69        83\n",
      "   macro avg       0.73      0.70      0.68        83\n",
      "weighted avg       0.74      0.69      0.68        83\n",
      "\n",
      "Total keywords:  195\n",
      "Total Tweets:  1019\n",
      "List of Keywords:\n",
      "\n",
      " ['cheese', 'chicken', 'milk', 'cream', 'butter', 'fruit', 'rice', 'water', 'bread', 'garlic', 'chocolate', 'sugar', 'coconut', 'fish', 'pasta', 'yogurt', 'pork', 'eggs', 'vegetables', 'cauliflower', 'nuts', 'cereal', 'potatoes', 'oats', 'cheesecake', 'crackers', 'cinnamon', 'muffin', 'goat', 'pesto', 'vinegar', 'honey', 'peanuts', 'oregano', 'flour', 'dough', 'aioli', 'buttermilk', 'coffee', 'syrup', 'tomatoes', 'bagel', 'blueberries', 'herbs', 'sausage', 'mushrooms', 'kale', 'celery', 'beans', 'soda', 'beef', 'tofu', 'base', 'onions', 'quinoa', 'margarine', 'oils', 'salt', 'walnuts', 'pudding', 'quiche', 'ricotta', 'strawberries', 'peas', 'bananas', 'arugula', 'beets', 'veal', 'meats', 'pineapple', 'olives', 'rabbit', 'fruits', 'granola', 'bacon', 'gravy', 'turkey', 'biscuits', 'parsley', 'basil', 'watermelon', 'quail', 'tuna', 'peppers', 'rosemary', 'lettuce', 'apples', 'tea', 'berries', 'avocados', 'pickles', 'kimchi', 'dates', 'scallops', 'yuzu', 'zucchini', 'cumin', 'lamb', 'miso', 'spelt', 'barley', 'popcorn', 'salsa', 'asparagus', 'broth', 'tortillas', 'pistachios', 'ghee', 'guacamole', 'cilantro', 'sausages', 'pate', 'leftovers', 'casseroles', 'cookies', 'doughnuts', 'guava', 'polenta', 'pies', 'ham', 'nutmeg', 'yeast', 'raspberries', 'cornmeal', 'cornstarch', 'grits', 'mustard', 'tamarind', 'cabbage', 'nectar', 'mint', 'greens', 'apricots', 'squash', 'cherimoya', 'grapes', 'coconuts', 'almonds', 'melons', 'pomegranate', 'thyme', 'eggplant', 'lentils', 'turnips', 'leeks', 'radishes', 'taro', 'cucumbers', 'pizza', 'hummus', 'pretzels', 'tempeh', 'pecans', 'flaxseed', 'horseradish', 'marinades', 'coleslaw', 'marshmallows', 'pectin', 'squid', 'kumquats', 'tahini', 'cherries', 'salami', 'macadamias', 'cashews', 'rye', 'rhubarb', 'formula', 'seafood', 'jicama', 'kohlrabi', 'honeydew', 'tapenade', 'chives', 'jerky', 'molasses', 'macaroons', 'plantains', 'caviar', 'buckwheat', 'farro', 'millet', 'teff', 'capers', 'mayonnaise', 'prosciutto', 'chorizo', 'bulgur', 'edamame', 'breadcrumbs', 'anchovies', 'radicchio', 'croutons', 'pumpkins'] \n",
      "\n",
      "\n",
      "~~~~~~~~~~~~~~~~~5~~~~~~~~~~~~~~~~~\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 35/2604 [00:00<00:07, 349.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 152/2604 [00:00<00:19, 128.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 226/2604 [00:02<00:41, 57.02it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 277/2604 [00:03<00:55, 41.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 333/2604 [00:05<00:56, 40.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 353/2604 [00:05<01:08, 32.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 377/2604 [00:06<01:05, 33.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 454/2604 [00:08<01:04, 33.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 505/2604 [00:10<01:16, 27.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 577/2604 [00:13<01:22, 24.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 601/2604 [00:14<01:37, 20.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n",
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 610/2604 [00:15<01:30, 21.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n",
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 637/2604 [00:16<01:26, 22.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n",
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 649/2604 [00:16<01:32, 21.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 661/2604 [00:17<01:29, 21.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n",
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 688/2604 [00:18<01:26, 22.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 715/2604 [00:19<01:28, 21.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 769/2604 [00:22<01:28, 20.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 816/2604 [00:25<01:41, 17.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 920/2604 [00:31<01:43, 16.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 956/2604 [00:33<01:43, 15.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 1024/2604 [00:37<01:41, 15.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 1056/2604 [00:40<01:41, 15.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████▏     | 1076/2604 [00:41<01:41, 15.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████▏     | 1080/2604 [00:41<01:43, 14.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 1108/2604 [00:43<01:40, 14.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 1126/2604 [00:44<01:42, 14.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 1214/2604 [00:51<01:41, 13.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 1224/2604 [00:51<01:45, 13.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 1248/2604 [00:53<01:40, 13.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 1262/2604 [00:54<01:42, 13.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1310/2604 [00:58<01:39, 13.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 1362/2604 [01:02<01:37, 12.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 1414/2604 [01:06<01:35, 12.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 1452/2604 [01:09<01:35, 12.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 1458/2604 [01:10<01:35, 12.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 1464/2604 [01:10<01:35, 11.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████▋    | 1466/2604 [01:11<01:39, 11.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 1698/2604 [01:31<01:24, 10.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 1722/2604 [01:33<01:22, 10.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 2009/2604 [02:05<01:13,  8.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 2028/2604 [02:07<01:11,  8.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 2226/2604 [02:33<00:51,  7.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 2270/2604 [02:39<00:46,  7.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 2422/2604 [03:01<00:26,  6.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 2593/2604 [03:26<00:01,  6.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2604/2604 [03:28<00:00, 12.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'ner']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
      "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  ------------  --------  ------  ------  ------  ------\n",
      "  0       0          0.00     13.83    0.06    0.07    0.06    0.00\n",
      "  0     200         59.96   1719.89   83.72   83.44   84.00    0.84\n",
      "  0     400         38.86    845.27   89.02   84.26   94.35    0.89\n",
      "  0     600         27.79    881.70   89.57   84.21   95.65    0.90\n",
      "  0     800         22.57   1068.00   90.80   85.37   96.96    0.91\n",
      "  1    1000         30.24   1065.00   91.95   89.67   94.35    0.92\n",
      "  1    1200         37.57   1320.58   92.95   89.44   96.75    0.93\n",
      "  2    1400         52.98   1222.75   94.65   92.59   96.80    0.95\n",
      "  3    1600         66.95   1317.17   95.99   95.30   96.69    0.96\n",
      "  4    1800        103.48   1226.31   96.94   96.01   97.89    0.97\n",
      "  5    2000        133.46   1204.98   98.02   97.53   98.51    0.98\n",
      "  6    2200        166.93   1055.55   98.71   98.28   99.14    0.99\n",
      "  8    2400        252.39    843.61   99.30   99.54   99.06    0.99\n",
      " 10    2600        256.54    688.52   99.54   99.53   99.55    1.00\n",
      " 12    2800        265.67    502.76   99.63   99.47   99.78    1.00\n",
      " 14    3000        305.75    485.94   99.76   99.64   99.88    1.00\n",
      " 15    3200        334.39    436.20   99.72   99.81   99.64    1.00\n",
      " 17    3400        385.42    356.88   99.61   99.92   99.31    1.00\n",
      " 19    3600        424.09    366.60   99.83   99.76   99.90    1.00\n",
      " 21    3800        371.28    302.79   99.81   99.75   99.87    1.00\n",
      " 23    4000        439.50    287.01   99.77   99.54   99.99    1.00\n",
      " 25    4200        503.63    248.32   99.82   99.69   99.95    1.00\n",
      " 26    4400        460.17    252.78   99.81   99.87   99.75    1.00\n",
      " 28    4600        493.51    266.61   99.81   99.68   99.94    1.00\n",
      " 30    4800        494.43    251.78   99.86   99.93   99.78    1.00\n",
      " 32    5000        525.34    227.03   99.93   99.90   99.96    1.00\n",
      " 34    5200        537.41    176.46   99.90   99.90   99.90    1.00\n",
      " 35    5400        631.94    210.69   99.92   99.89   99.95    1.00\n",
      " 37    5600        568.91    191.61   99.91   99.89   99.93    1.00\n",
      " 39    5800        688.39    183.97   99.90   99.83   99.96    1.00\n",
      " 41    6000        633.86    200.37   99.93   99.90   99.96    1.00\n",
      " 43    6200        657.24    178.27   99.86   99.84   99.87    1.00\n",
      " 44    6400        609.48    189.95   99.89   99.93   99.86    1.00\n",
      " 46    6600        597.98    173.30   99.82   99.95   99.69    1.00\n",
      "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
      "output/model-last\n",
      "\n",
      "Total keywords:  195\n",
      "List of Keywords:\n",
      "\n",
      " ['cheese', 'chicken', 'milk', 'cream', 'butter', 'fruit', 'rice', 'water', 'bread', 'garlic', 'chocolate', 'sugar', 'coconut', 'fish', 'pasta', 'yogurt', 'pork', 'eggs', 'vegetables', 'cauliflower', 'nuts', 'cereal', 'potatoes', 'oats', 'cheesecake', 'crackers', 'cinnamon', 'muffin', 'goat', 'pesto', 'vinegar', 'honey', 'peanuts', 'oregano', 'flour', 'dough', 'aioli', 'buttermilk', 'coffee', 'syrup', 'tomatoes', 'bagel', 'blueberries', 'herbs', 'sausage', 'mushrooms', 'kale', 'celery', 'beans', 'soda', 'beef', 'tofu', 'base', 'onions', 'quinoa', 'margarine', 'oils', 'salt', 'walnuts', 'pudding', 'quiche', 'ricotta', 'strawberries', 'peas', 'bananas', 'arugula', 'beets', 'veal', 'meats', 'pineapple', 'olives', 'rabbit', 'fruits', 'granola', 'bacon', 'gravy', 'turkey', 'biscuits', 'parsley', 'basil', 'watermelon', 'quail', 'tuna', 'peppers', 'rosemary', 'lettuce', 'apples', 'tea', 'berries', 'avocados', 'pickles', 'kimchi', 'dates', 'scallops', 'yuzu', 'zucchini', 'cumin', 'lamb', 'miso', 'spelt', 'barley', 'popcorn', 'salsa', 'asparagus', 'broth', 'tortillas', 'pistachios', 'ghee', 'guacamole', 'cilantro', 'sausages', 'pate', 'leftovers', 'casseroles', 'cookies', 'doughnuts', 'guava', 'polenta', 'pies', 'ham', 'nutmeg', 'yeast', 'raspberries', 'cornmeal', 'cornstarch', 'grits', 'mustard', 'tamarind', 'cabbage', 'nectar', 'mint', 'greens', 'apricots', 'squash', 'cherimoya', 'grapes', 'coconuts', 'almonds', 'melons', 'pomegranate', 'thyme', 'eggplant', 'lentils', 'turnips', 'leeks', 'radishes', 'taro', 'cucumbers', 'pizza', 'hummus', 'pretzels', 'tempeh', 'pecans', 'flaxseed', 'horseradish', 'marinades', 'coleslaw', 'marshmallows', 'pectin', 'squid', 'kumquats', 'tahini', 'cherries', 'salami', 'macadamias', 'cashews', 'rye', 'rhubarb', 'formula', 'seafood', 'jicama', 'kohlrabi', 'honeydew', 'tapenade', 'chives', 'jerky', 'molasses', 'macaroons', 'plantains', 'caviar', 'buckwheat', 'farro', 'millet', 'teff', 'capers', 'mayonnaise', 'prosciutto', 'chorizo', 'bulgur', 'edamame', 'breadcrumbs', 'anchovies', 'radicchio', 'croutons', 'pumpkins'] \n",
      "\n",
      "\n",
      "[[21 23]\n",
      " [ 4 35]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.48      0.61        44\n",
      "           0       0.60      0.90      0.72        39\n",
      "\n",
      "    accuracy                           0.67        83\n",
      "   macro avg       0.72      0.69      0.67        83\n",
      "weighted avg       0.73      0.67      0.66        83\n",
      "\n",
      "Total keywords:  218\n",
      "Total Tweets:  2604\n",
      "List of Keywords:\n",
      "\n",
      " ['cheese', 'chicken', 'milk', 'cream', 'butter', 'fruit', 'rice', 'water', 'bread', 'garlic', 'chocolate', 'sugar', 'coconut', 'fish', 'pasta', 'yogurt', 'pork', 'eggs', 'vegetables', 'cauliflower', 'nuts', 'cereal', 'potatoes', 'oats', 'cheesecake', 'crackers', 'cinnamon', 'muffin', 'goat', 'pesto', 'vinegar', 'honey', 'peanuts', 'oregano', 'flour', 'dough', 'aioli', 'buttermilk', 'coffee', 'syrup', 'tomatoes', 'bagel', 'blueberries', 'herbs', 'sausage', 'mushrooms', 'kale', 'celery', 'beans', 'soda', 'beef', 'tofu', 'base', 'onions', 'quinoa', 'margarine', 'oils', 'salt', 'walnuts', 'pudding', 'quiche', 'ricotta', 'strawberries', 'peas', 'bananas', 'arugula', 'beets', 'veal', 'meats', 'pineapple', 'olives', 'rabbit', 'fruits', 'granola', 'bacon', 'gravy', 'turkey', 'biscuits', 'parsley', 'basil', 'watermelon', 'quail', 'tuna', 'peppers', 'rosemary', 'lettuce', 'apples', 'tea', 'berries', 'avocados', 'pickles', 'kimchi', 'dates', 'scallops', 'yuzu', 'zucchini', 'cumin', 'lamb', 'miso', 'spelt', 'barley', 'popcorn', 'salsa', 'asparagus', 'broth', 'tortillas', 'pistachios', 'ghee', 'guacamole', 'cilantro', 'sausages', 'pate', 'leftovers', 'casseroles', 'cookies', 'doughnuts', 'guava', 'polenta', 'pies', 'ham', 'nutmeg', 'yeast', 'raspberries', 'cornmeal', 'cornstarch', 'grits', 'mustard', 'tamarind', 'cabbage', 'nectar', 'mint', 'greens', 'apricots', 'squash', 'cherimoya', 'grapes', 'coconuts', 'almonds', 'melons', 'pomegranate', 'thyme', 'eggplant', 'lentils', 'turnips', 'leeks', 'radishes', 'taro', 'cucumbers', 'pizza', 'hummus', 'pretzels', 'tempeh', 'pecans', 'flaxseed', 'horseradish', 'marinades', 'coleslaw', 'marshmallows', 'pectin', 'squid', 'kumquats', 'tahini', 'cherries', 'salami', 'macadamias', 'cashews', 'rye', 'rhubarb', 'formula', 'seafood', 'jicama', 'kohlrabi', 'honeydew', 'tapenade', 'chives', 'jerky', 'molasses', 'macaroons', 'plantains', 'caviar', 'buckwheat', 'farro', 'millet', 'teff', 'capers', 'mayonnaise', 'prosciutto', 'chorizo', 'bulgur', 'edamame', 'breadcrumbs', 'anchovies', 'radicchio', 'croutons', 'pumpkins', 'dips', 'eggnog', 'kefir', 'venison', 'pheasant', 'cranberries', 'capon', 'duckling', 'giblets', 'turducken', 'herring', 'dinners', 'tapiocas', 'okra', 'relish', 'chutney', 'rutabagas', 'goose', 'pastrami', 'applesauce', 'lemongrass', 'cantaloupe', 'bratwurst'] \n",
      "\n",
      "\n",
      "~~~~~~~~~~~~~~~~~6~~~~~~~~~~~~~~~~~\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 30/2604 [00:00<00:08, 294.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 151/2604 [00:01<00:21, 112.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 231/2604 [00:02<00:36, 65.58it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 280/2604 [00:03<00:45, 50.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 336/2604 [00:04<00:52, 42.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 353/2604 [00:05<00:59, 37.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 377/2604 [00:05<01:07, 32.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 453/2604 [00:08<01:06, 32.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 506/2604 [00:09<01:13, 28.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 578/2604 [00:12<01:19, 25.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 602/2604 [00:13<01:21, 24.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n",
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 611/2604 [00:14<01:27, 22.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n",
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 638/2604 [00:15<01:25, 22.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n",
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 650/2604 [00:15<01:28, 22.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 662/2604 [00:16<01:28, 21.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n",
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 689/2604 [00:17<01:24, 22.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 713/2604 [00:18<01:25, 22.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 770/2604 [00:21<01:28, 20.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 816/2604 [00:23<01:36, 18.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 920/2604 [00:30<01:42, 16.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 956/2604 [00:32<01:42, 16.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 1024/2604 [00:36<01:40, 15.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 1056/2604 [00:38<01:43, 14.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 1073/2604 [00:41<05:08,  4.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 1081/2604 [00:42<02:57,  8.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 1107/2604 [00:44<02:10, 11.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 1127/2604 [00:45<01:46, 13.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 1213/2604 [00:51<01:39, 13.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 1225/2604 [00:52<01:41, 13.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 1247/2604 [00:56<03:41,  6.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 1262/2604 [00:58<03:11,  7.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1310/2604 [01:03<01:45, 12.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 1362/2604 [01:07<01:35, 12.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 1415/2604 [01:13<01:51, 10.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 1452/2604 [01:17<01:36, 11.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 1458/2604 [01:17<01:37, 11.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 1464/2604 [01:18<01:44, 10.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████▋    | 1466/2604 [01:18<01:46, 10.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 1697/2604 [01:44<01:48,  8.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 1722/2604 [01:47<01:41,  8.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 2009/2604 [02:22<01:16,  7.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 2028/2604 [02:25<01:18,  7.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 2033/2604 [02:25<01:15,  7.54it/s]"
     ]
    }
   ],
   "source": [
    "trainModel(training_data)\n",
    "#print(keywords)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">@ellelovexx haaaaa i want mac &amp;amp; \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    cheese\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">FOOD</span>\n",
       "</mark>\n",
       " toooooo!!! hahahaha hey..i still got the one u left here...i guess im making that today Oo lol</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">@Sabbyaz aiyooooo maybe \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    chocolate\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">FOOD</span>\n",
       "</mark>\n",
       " will help? \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    chocolate\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">FOOD</span>\n",
       "</mark>\n",
       " helps in most situations</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Not wanting to get rid of her rabbits. This is going to be a great day..</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">@Jonasbrothers thats so exciting! u are coming to south america in a few hours! but not to colombia hope u have fun here! we love u!!</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">@philispig Is competition around the corner? if not take it slow for at least a week. Twisted my ankle back in jc, awfully painful.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">@rawrmtoxic i have too much veggies and rice. I WANT PIZZA BUT NO. RECESSION.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">@cuteredshoes GREAT! now i want chocolate.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Thought Adventure Land was good.. not as good as Superbad</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Zzzzz....packing and cleaning all day. Pizza and glasses of red wine....now...paint the 4th room....ggrrrrr, don't want to, but I must.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">@_Jaska \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Some\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">FOOD</span>\n",
       "</mark>\n",
       " things... they just never get old. http://tinyurl.com/holdisgiantcherry I miss Maya.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Gr8t day! Love how God hears and answers my whispers. Love him cause he rescued me</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Its raining and its cold outside. Winter coats again.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">just woken up, finally got to sleep last night, alone, on the couch watching one tree hill eating \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    cheese\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">FOOD</span>\n",
       "</mark>\n",
       " and crackers!</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">we can't get the dog. i'm seriously sad, now.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Bananas, Rice, Applesauce, Toast...</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nlp = spacy.load(MODEL_PATH)\n",
    "for tweet in sampleTweets:\n",
    "    ent_recognize(tweet)\n",
    "#ent_recognize(\"My friend likes to drink milk and eat fish and chicken\")\n",
    "#ent_recognize(\"My friend is a chicken\")\n",
    "#ent_recognize(\"A chicken is a wild animal.\")\n",
    "#ent_recognize(\"The chicken is a wild animal.\")\n",
    "\n",
    "#rankTweet(\"sugar\")\n",
    "#eval_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#eval_model()\n",
    "# show_tp()\n",
    "# show_tn()\n",
    "# show_fp()\n",
    "#show_fn()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rankTweet(\"Hello chicken\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['chicken', 'milk']\n"
     ]
    }
   ],
   "source": [
    "print(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                tweet  food\n",
      "0   just microwaved a kashi chicken and spinach th...     1\n",
      "1   <USERNAME> thats really sad i wolud hate that!...     1\n",
      "2   <USERNAME> and it took me my entire walk to th...     0\n",
      "3   just finished cooking spag bol from scratch.. ...     1\n",
      "4   oh noooooo kath is back from annual leave!!!!!...     0\n",
      "..                                                ...   ...\n",
      "78  sick roomie gave me her cold my throats sore (...     0\n",
      "79  no flying to ponca city today for breakfast oa...     1\n",
      "80  just walked by marks&amp;spencers food n didn'...     1\n",
      "81  if lucas till and taylor swift start dating i ...     0\n",
      "82                          bed time. back to reality     0\n",
      "\n",
      "[83 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import sample \n",
    "test_data2 = pd.read_csv(TEST_DATA_PATH)\n",
    "sampleTweets = sample(list(test_data2['tweet']), 15)\n",
    "#int(test_data['tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
